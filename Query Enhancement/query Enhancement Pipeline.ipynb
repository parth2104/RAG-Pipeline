{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1409b42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\R'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\R'\n",
      "C:\\Users\\PARTH\\AppData\\Local\\Temp\\ipykernel_1656\\1421567176.py:4: SyntaxWarning: invalid escape sequence '\\R'\n",
      "  doc=TextLoader(\"D:\\RAG\\ml_ai_corpus.txt\",encoding=\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TextSplitter\n",
    "\n",
    "doc=TextLoader(\"D:\\RAG\\ml_ai_corpus.txt\",encoding=\"utf-8\")\n",
    "\n",
    "docs=doc.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0838aba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning & Artificial Intelligence - Core Concepts and Overview\\n\\nSection 1 — Overview\\nMachine Learning (ML) is a subfield of Artificial Intelligence (AI) that focuses on developing algorithms and statistical models that allow computers to perform tasks without explicit instructions. Instead, ML systems learn patterns from data and use those patterns to make predictions or decisions. AI is a broader discipline that includes ML as well as symbolic reasoning, planning, robotics, and other approaches to create systems that can simulate aspects of human intelligence.\\n\\nSection 2 — Brief History\\nEarly AI research (1950s–1970s) explored symbolic reasoning and rule-based systems. ML emerged more clearly as computational power and data availability increased; key milestones include the development of decision trees, support vector machines, and neural networks. The 2010s brought deep learning advances, enabled by larger datasets and GPUs, making breakthroughs in computer vision, natural language processing, and speech recognition.\\n\\nSection 3 — Key Concepts\\n- Dataset: A collection of examples used to train and test ML models (features/inputs and labels/outputs).\\n- Feature: An individual measurable property or characteristic of an instance in the dataset.\\n- Label/Target: The value or class the model is trying to predict.\\n- Training: The process of fitting a model to data.\\n- Validation: Tuning hyperparameters and selecting the best model configuration.\\n- Testing: Evaluating the final model on unseen data to estimate performance.\\n- Overfitting: When a model learns noise or specific patterns in training data and performs poorly on new data.\\n- Underfitting: When a model is too simple to capture underlying patterns in the data.\\n\\nSection 4 — Types of Learning\\n- Supervised Learning: Models learn a mapping from inputs to outputs using labeled data (e.g., classification, regression).\\n- Unsupervised Learning: Models find structure in unlabeled data (e.g., clustering, dimensionality reduction).\\n- Semi-supervised Learning: Combining small amounts of labeled data with larger unlabeled sets.\\n- Reinforcement Learning: An agent learns to take actions in an environment to maximize cumulative reward.\\n\\nSection 5 — Common Algorithms & Models\\n- Linear Regression: Predicts a continuous value from input features.\\n- Logistic Regression: Binary classification model that outputs probabilities.\\n- Decision Trees and Random Forests: Tree-based models useful for tabular data.\\n- Support Vector Machines (SVM): Effective in high-dimensional spaces.\\n- k-Nearest Neighbors (k-NN): Instance-based learning using distance measures.\\n- Gradient Boosting Machines (e.g., XGBoost, LightGBM): Powerful ensemble methods for many practical tasks.\\n- Neural Networks and Deep Learning: Layers of parameterized functions trained via backpropagation. Includes specialized architectures:\\n  - Convolutional Neural Networks (CNNs) for image data.\\n  - Recurrent Neural Networks (RNNs) and Transformers for sequential and language data.\\n- Transformers: Architecture based on attention mechanisms; state-of-the-art for many NLP tasks.\\n\\nSection 6 — Data Preparation & Feature Engineering\\n- Data cleaning: Handling missing values, removing duplicates, correcting errors.\\n- Normalization/Standardization: Scaling features so models train better.\\n- Encoding categorical variables: One-hot encoding, label encoding, and embeddings.\\n- Feature selection and extraction: Reduce dimensionality and remove irrelevant features.\\n- Data augmentation: Synthetically expand datasets (common in images and audio).\\n\\nSection 7 — Model Evaluation & Metrics\\n- Classification metrics: Accuracy, Precision, Recall, F1-score, ROC-AUC.\\n- Regression metrics: Mean Squared Error (MSE), Root MSE, Mean Absolute Error (MAE), R².\\n- Cross-validation: Splitting data into folds for more robust evaluation.\\n- Confusion matrix: Visualizing true vs predicted class counts.\\n- Calibration and bias-variance tradeoff: Balancing model complexity and generalization.\\n\\nSection 8 — Deployment & Serving\\n- Model serialization: Saving models (pickle, joblib, ONNX, SavedModel).\\n- Serving frameworks: TensorFlow Serving, TorchServe, FastAPI/Flask wrappers.\\n- Containerization & orchestration: Docker, Kubernetes for scalable deployments.\\n- Monitoring: Track model performance drift, latency, and data distribution changes.\\n\\nSection 9 — Responsible AI & Ethics\\n- Fairness: Detecting and mitigating bias across demographic groups.\\n- Explainability: Tools and techniques (SHAP, LIME) to explain model predictions.\\n- Privacy: Differential privacy, federated learning for privacy-preserving ML.\\n- Safety: Preventing harmful or unexpected model behavior; human-in-the-loop systems.\\n\\nSection 10 — Common Applications\\n- Computer Vision: Image classification, object detection, segmentation.\\n- Natural Language Processing (NLP): Text classification, translation, summarization, question answering.\\n- Recommendation Systems: Collaborative and content-based filtering.\\n- Time Series Forecasting: Demand forecasting, anomaly detection.\\n- Autonomous Systems: Robotics, self-driving vehicles.\\n- Healthcare, Finance, Retail, Manufacturing: Wide domain-specific uses.\\n\\nSection 11 — Datasets & Resources\\n- Example dataset types: Image datasets (ImageNet, CIFAR), text corpora (Wikipedia, OpenWebText), tabular datasets (UCI repository), time-series datasets.\\n- Benchmarking: Use standardized datasets to compare models fairly.\\n\\nSection 12 — Quick Tips for RAG (Retrieval-Augmented Generation) Use\\n- Clean and structure text: Use headings, short paragraphs, and bullet lists to improve retrieval relevance.\\n- Split long documents into chunks: 200–800 tokens per chunk is common.\\n- Add metadata: source, section, date to each document chunk to help filtering and provenance.\\n- Prefer plain text or simple markdown: Easier for tokenization and embedding.\\n\\nSection 13 — Suggested Metadata Example (for each chunk)\\n- source: \"ml_ai_corpus.txt\"\\n- section: \"Key Concepts\"\\n- created: \"2025-11-25\"\\n- author: \"Generated for RAG ingestion\"\\n\\nSection 14 — Further Reading (non-exhaustive)\\n- Introductory textbooks and online courses on ML and AI\\n- Research papers and tutorials for specialized topics\\n- Official documentation for frameworks (TensorFlow, PyTorch, scikit-learn)\\n\\n--- End of file ---\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_string=docs[0].page_content\n",
    "text_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82ec6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page conntent Machine Learning & Artificial Intelligence - Core Concepts and Overview\n",
      "\n",
      "Section 1 — Overview\n",
      "Machine Learning (ML) is a subfield of Artificial Intelligence (AI) that focuses on developing algorithms and statistical models that allow computers to perform tasks without explicit instructions. Instead, ML systems learn patterns from data and use those patterns to make predictions or decisions. AI is a broader discipline that includes ML as well as symbolic reasoning, planning, robotics, and other approaches to create systems that can simulate aspects of human intelligence.\n",
      "\n",
      "Section 2 — Brief History\n",
      "Early AI research (1950s–1970s) explored symbolic reasoning and rule-based systems. ML emerged more clearly as computational power and data availability increased; key milestones include the devel  \n",
      "matadat metadata {'source': 'D:\\\\RAG\\\\ml_ai_corpus.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"page conntent {docs[0].page_content[:800]}  \")\n",
    "print(f\"matadat metadata {docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c484b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght 20\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk=RecursiveCharacterTextSplitter(\n",
    "    separators=[\",\",\".\",\"/n\",\"/n/n\"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "chunks=chunk.split_text(text_string)\n",
    "print(f\"lenght {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02cb9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os \n",
    "\n",
    "embed=OpenAIEmbeddings(\n",
    "    api_key=os.getenv(\"api_key\"),\n",
    "    model=\"text-embedding-3-small\",\n",
    "    base_url=os.getenv(\"endpoints\")\n",
    ")\n",
    "\n",
    "vector=embed.embed_documents(chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0982ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vector = Chroma.from_texts(\n",
    "    texts=chunks,\n",
    "    embedding=embed,\n",
    "    persist_directory=\"pipeline\",\n",
    "    collection_name=\"Queryenhancement\"\n",
    ")\n",
    "\n",
    "retriever = vector.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3877cd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001EFAB1DD400>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b5a298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    model=\"gpt-5-nano-2025-08-07\",\n",
    "    api_key=os.getenv(\"api_key\"),\n",
    "    openai_api_base=os.getenv(\"endpoints\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ff751e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001EFADC28AD0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001EFADC28EC0>, root_client=<openai.OpenAI object at 0x000001EFADBBEE90>, root_async_client=<openai.AsyncOpenAI object at 0x000001EFADBBF4D0>, model_name='gpt-5-nano-2025-08-07', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.euron.one/api/v1/euri')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b6ede25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts  import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "prompt_llm=PromptTemplate.from_template(\n",
    "    '''You are an AI assistant that enhances user queries for better information retrieval.\n",
    "\n",
    "Your task is to take the original user query and generate an improved, expanded version of the query without changing its meaning.\n",
    "\n",
    "Follow these rules:\n",
    "- Keep the original intent exactly the same.\n",
    "- Add relevant keywords, synonyms, and related phrases that might help retrieval.\n",
    "- Include domain-specific terminology if applicable.\n",
    "- Be concise and avoid unnecessary words.\n",
    "- Do NOT answer the query. Only rewrite and enhance it.\n",
    "- Return only the enhanced query. No explanations.\n",
    "\n",
    "Original Query: {query}\n",
    "\n",
    "Enhanced Query:\n",
    "'''\n",
    ")\n",
    "\n",
    "query_expansion_chain=prompt_llm | llm |StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31cb9ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='You are an AI assistant that enhances user queries for better information retrieval.\\n\\nYour task is to take the original user query and generate an improved, expanded version of the query without changing its meaning.\\n\\nFollow these rules:\\n- Keep the original intent exactly the same.\\n- Add relevant keywords, synonyms, and related phrases that might help retrieval.\\n- Include domain-specific terminology if applicable.\\n- Be concise and avoid unnecessary words.\\n- Do NOT answer the query. Only rewrite and enhance it.\\n- Return only the enhanced query. No explanations.\\n\\nOriginal Query: {query}\\n\\nEnhanced Query:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001EFADC28AD0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001EFADC28EC0>, root_client=<openai.OpenAI object at 0x000001EFADBBEE90>, root_async_client=<openai.AsyncOpenAI object at 0x000001EFADBBF4D0>, model_name='gpt-5-nano-2025-08-07', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.euron.one/api/v1/euri')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d72c455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain framework for LLM-powered applications; LangChain Python and LangChain.js; chains, agents, prompts/templates, tools, memory; vector stores and embeddings (FAISS, Pinecone, Chroma); tool integrations; tutorials and documentation.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_chain.invoke({\"query\":\"langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bbc2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt_template=ChatPromptTemplate.from_template(\"\"\"\n",
    "answer the question based on abbove context below \n",
    " context :{context}\n",
    "question :{input}\"\"\")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm=llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a40ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "\n",
    "rag_pipeline = (\n",
    "    RunnableMap({\n",
    "        \"input\": RunnablePassthrough(),\n",
    "        \"context\": lambda x: retriever.invoke(\n",
    "            query_expansion_chain.invoke(x[\"input\"])\n",
    "        )\n",
    "    })\n",
    "    | document_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f3505ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query={\"input\":\" what is AI and ML ?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a33297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=rag_pipeline.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ed4f04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Artificial Intelligence (AI): A broad field that aims to create systems capable of simulating aspects of human intelligence. It includes ML and other approaches such as symbolic reasoning, planning, robotics, and more.\\n\\n- Machine Learning (ML): A subfield of AI that focuses on developing algorithms and statistical models that allow computers to perform tasks without explicit instructions. ML systems learn patterns from data and use those patterns to make predictions or decisions. Key ideas in ML include datasets, features, labels (targets), training, and validation.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062b615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
